{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement logistic regression using Python /R to perform classification on a given \n",
    "dataset. \n",
    "2. Compute Confusion Matrix of findTP,FP,TN,FN,Accuracy, Error Rate, Precision,Recall on \n",
    "the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Social_Network_Ads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15691863</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15706071</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15654296</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15755018</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15594041</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0    15624510    Male   19            19000          0\n",
       "1    15810944    Male   35            20000          0\n",
       "2    15668575  Female   26            43000          0\n",
       "3    15603246  Female   27            57000          0\n",
       "4    15804002    Male   19            76000          0\n",
       "..        ...     ...  ...              ...        ...\n",
       "395  15691863  Female   46            41000          1\n",
       "396  15706071    Male   51            23000          1\n",
       "397  15654296  Female   50            20000          1\n",
       "398  15755018    Male   36            33000          0\n",
       "399  15594041  Female   49            36000          1\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID             int64\n",
       "Gender             object\n",
       "Age                 int64\n",
       "EstimatedSalary     int64\n",
       "Purchased           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000e+02</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.569154e+07</td>\n",
       "      <td>37.655000</td>\n",
       "      <td>69742.500000</td>\n",
       "      <td>0.357500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.165832e+04</td>\n",
       "      <td>10.482877</td>\n",
       "      <td>34096.960282</td>\n",
       "      <td>0.479864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.556669e+07</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.562676e+07</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>43000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.569434e+07</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.575036e+07</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>88000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.581524e+07</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User ID         Age  EstimatedSalary   Purchased\n",
       "count  4.000000e+02  400.000000       400.000000  400.000000\n",
       "mean   1.569154e+07   37.655000     69742.500000    0.357500\n",
       "std    7.165832e+04   10.482877     34096.960282    0.479864\n",
       "min    1.556669e+07   18.000000     15000.000000    0.000000\n",
       "25%    1.562676e+07   29.750000     43000.000000    0.000000\n",
       "50%    1.569434e+07   37.000000     70000.000000    0.000000\n",
       "75%    1.575036e+07   46.000000     88000.000000    1.000000\n",
       "max    1.581524e+07   60.000000    150000.000000    1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID            0\n",
       "Gender             0\n",
       "Age                0\n",
       "EstimatedSalary    0\n",
       "Purchased          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(df['Age'],bins=6,color='grey',rwidth=0.90)\n",
    "plt.title('Distribution of Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,[2,3]].values\n",
    "Y=df.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    19,  19000],\n",
       "       [    35,  20000],\n",
       "       [    26,  43000],\n",
       "       [    27,  57000],\n",
       "       [    19,  76000],\n",
       "       [    27,  58000],\n",
       "       [    27,  84000],\n",
       "       [    32, 150000],\n",
       "       [    25,  33000],\n",
       "       [    35,  65000],\n",
       "       [    26,  80000],\n",
       "       [    26,  52000],\n",
       "       [    20,  86000],\n",
       "       [    32,  18000],\n",
       "       [    18,  82000],\n",
       "       [    29,  80000],\n",
       "       [    47,  25000],\n",
       "       [    45,  26000],\n",
       "       [    46,  28000],\n",
       "       [    48,  29000],\n",
       "       [    45,  22000],\n",
       "       [    47,  49000],\n",
       "       [    48,  41000],\n",
       "       [    45,  22000],\n",
       "       [    46,  23000],\n",
       "       [    47,  20000],\n",
       "       [    49,  28000],\n",
       "       [    47,  30000],\n",
       "       [    29,  43000],\n",
       "       [    31,  18000],\n",
       "       [    31,  74000],\n",
       "       [    27, 137000],\n",
       "       [    21,  16000],\n",
       "       [    28,  44000],\n",
       "       [    27,  90000],\n",
       "       [    35,  27000],\n",
       "       [    33,  28000],\n",
       "       [    30,  49000],\n",
       "       [    26,  72000],\n",
       "       [    27,  31000],\n",
       "       [    27,  17000],\n",
       "       [    33,  51000],\n",
       "       [    35, 108000],\n",
       "       [    30,  15000],\n",
       "       [    28,  84000],\n",
       "       [    23,  20000],\n",
       "       [    25,  79000],\n",
       "       [    27,  54000],\n",
       "       [    30, 135000],\n",
       "       [    31,  89000],\n",
       "       [    24,  32000],\n",
       "       [    18,  44000],\n",
       "       [    29,  83000],\n",
       "       [    35,  23000],\n",
       "       [    27,  58000],\n",
       "       [    24,  55000],\n",
       "       [    23,  48000],\n",
       "       [    28,  79000],\n",
       "       [    22,  18000],\n",
       "       [    32, 117000],\n",
       "       [    27,  20000],\n",
       "       [    25,  87000],\n",
       "       [    23,  66000],\n",
       "       [    32, 120000],\n",
       "       [    59,  83000],\n",
       "       [    24,  58000],\n",
       "       [    24,  19000],\n",
       "       [    23,  82000],\n",
       "       [    22,  63000],\n",
       "       [    31,  68000],\n",
       "       [    25,  80000],\n",
       "       [    24,  27000],\n",
       "       [    20,  23000],\n",
       "       [    33, 113000],\n",
       "       [    32,  18000],\n",
       "       [    34, 112000],\n",
       "       [    18,  52000],\n",
       "       [    22,  27000],\n",
       "       [    28,  87000],\n",
       "       [    26,  17000],\n",
       "       [    30,  80000],\n",
       "       [    39,  42000],\n",
       "       [    20,  49000],\n",
       "       [    35,  88000],\n",
       "       [    30,  62000],\n",
       "       [    31, 118000],\n",
       "       [    24,  55000],\n",
       "       [    28,  85000],\n",
       "       [    26,  81000],\n",
       "       [    35,  50000],\n",
       "       [    22,  81000],\n",
       "       [    30, 116000],\n",
       "       [    26,  15000],\n",
       "       [    29,  28000],\n",
       "       [    29,  83000],\n",
       "       [    35,  44000],\n",
       "       [    35,  25000],\n",
       "       [    28, 123000],\n",
       "       [    35,  73000],\n",
       "       [    28,  37000],\n",
       "       [    27,  88000],\n",
       "       [    28,  59000],\n",
       "       [    32,  86000],\n",
       "       [    33, 149000],\n",
       "       [    19,  21000],\n",
       "       [    21,  72000],\n",
       "       [    26,  35000],\n",
       "       [    27,  89000],\n",
       "       [    26,  86000],\n",
       "       [    38,  80000],\n",
       "       [    39,  71000],\n",
       "       [    37,  71000],\n",
       "       [    38,  61000],\n",
       "       [    37,  55000],\n",
       "       [    42,  80000],\n",
       "       [    40,  57000],\n",
       "       [    35,  75000],\n",
       "       [    36,  52000],\n",
       "       [    40,  59000],\n",
       "       [    41,  59000],\n",
       "       [    36,  75000],\n",
       "       [    37,  72000],\n",
       "       [    40,  75000],\n",
       "       [    35,  53000],\n",
       "       [    41,  51000],\n",
       "       [    39,  61000],\n",
       "       [    42,  65000],\n",
       "       [    26,  32000],\n",
       "       [    30,  17000],\n",
       "       [    26,  84000],\n",
       "       [    31,  58000],\n",
       "       [    33,  31000],\n",
       "       [    30,  87000],\n",
       "       [    21,  68000],\n",
       "       [    28,  55000],\n",
       "       [    23,  63000],\n",
       "       [    20,  82000],\n",
       "       [    30, 107000],\n",
       "       [    28,  59000],\n",
       "       [    19,  25000],\n",
       "       [    19,  85000],\n",
       "       [    18,  68000],\n",
       "       [    35,  59000],\n",
       "       [    30,  89000],\n",
       "       [    34,  25000],\n",
       "       [    24,  89000],\n",
       "       [    27,  96000],\n",
       "       [    41,  30000],\n",
       "       [    29,  61000],\n",
       "       [    20,  74000],\n",
       "       [    26,  15000],\n",
       "       [    41,  45000],\n",
       "       [    31,  76000],\n",
       "       [    36,  50000],\n",
       "       [    40,  47000],\n",
       "       [    31,  15000],\n",
       "       [    46,  59000],\n",
       "       [    29,  75000],\n",
       "       [    26,  30000],\n",
       "       [    32, 135000],\n",
       "       [    32, 100000],\n",
       "       [    25,  90000],\n",
       "       [    37,  33000],\n",
       "       [    35,  38000],\n",
       "       [    33,  69000],\n",
       "       [    18,  86000],\n",
       "       [    22,  55000],\n",
       "       [    35,  71000],\n",
       "       [    29, 148000],\n",
       "       [    29,  47000],\n",
       "       [    21,  88000],\n",
       "       [    34, 115000],\n",
       "       [    26, 118000],\n",
       "       [    34,  43000],\n",
       "       [    34,  72000],\n",
       "       [    23,  28000],\n",
       "       [    35,  47000],\n",
       "       [    25,  22000],\n",
       "       [    24,  23000],\n",
       "       [    31,  34000],\n",
       "       [    26,  16000],\n",
       "       [    31,  71000],\n",
       "       [    32, 117000],\n",
       "       [    33,  43000],\n",
       "       [    33,  60000],\n",
       "       [    31,  66000],\n",
       "       [    20,  82000],\n",
       "       [    33,  41000],\n",
       "       [    35,  72000],\n",
       "       [    28,  32000],\n",
       "       [    24,  84000],\n",
       "       [    19,  26000],\n",
       "       [    29,  43000],\n",
       "       [    19,  70000],\n",
       "       [    28,  89000],\n",
       "       [    34,  43000],\n",
       "       [    30,  79000],\n",
       "       [    20,  36000],\n",
       "       [    26,  80000],\n",
       "       [    35,  22000],\n",
       "       [    35,  39000],\n",
       "       [    49,  74000],\n",
       "       [    39, 134000],\n",
       "       [    41,  71000],\n",
       "       [    58, 101000],\n",
       "       [    47,  47000],\n",
       "       [    55, 130000],\n",
       "       [    52, 114000],\n",
       "       [    40, 142000],\n",
       "       [    46,  22000],\n",
       "       [    48,  96000],\n",
       "       [    52, 150000],\n",
       "       [    59,  42000],\n",
       "       [    35,  58000],\n",
       "       [    47,  43000],\n",
       "       [    60, 108000],\n",
       "       [    49,  65000],\n",
       "       [    40,  78000],\n",
       "       [    46,  96000],\n",
       "       [    59, 143000],\n",
       "       [    41,  80000],\n",
       "       [    35,  91000],\n",
       "       [    37, 144000],\n",
       "       [    60, 102000],\n",
       "       [    35,  60000],\n",
       "       [    37,  53000],\n",
       "       [    36, 126000],\n",
       "       [    56, 133000],\n",
       "       [    40,  72000],\n",
       "       [    42,  80000],\n",
       "       [    35, 147000],\n",
       "       [    39,  42000],\n",
       "       [    40, 107000],\n",
       "       [    49,  86000],\n",
       "       [    38, 112000],\n",
       "       [    46,  79000],\n",
       "       [    40,  57000],\n",
       "       [    37,  80000],\n",
       "       [    46,  82000],\n",
       "       [    53, 143000],\n",
       "       [    42, 149000],\n",
       "       [    38,  59000],\n",
       "       [    50,  88000],\n",
       "       [    56, 104000],\n",
       "       [    41,  72000],\n",
       "       [    51, 146000],\n",
       "       [    35,  50000],\n",
       "       [    57, 122000],\n",
       "       [    41,  52000],\n",
       "       [    35,  97000],\n",
       "       [    44,  39000],\n",
       "       [    37,  52000],\n",
       "       [    48, 134000],\n",
       "       [    37, 146000],\n",
       "       [    50,  44000],\n",
       "       [    52,  90000],\n",
       "       [    41,  72000],\n",
       "       [    40,  57000],\n",
       "       [    58,  95000],\n",
       "       [    45, 131000],\n",
       "       [    35,  77000],\n",
       "       [    36, 144000],\n",
       "       [    55, 125000],\n",
       "       [    35,  72000],\n",
       "       [    48,  90000],\n",
       "       [    42, 108000],\n",
       "       [    40,  75000],\n",
       "       [    37,  74000],\n",
       "       [    47, 144000],\n",
       "       [    40,  61000],\n",
       "       [    43, 133000],\n",
       "       [    59,  76000],\n",
       "       [    60,  42000],\n",
       "       [    39, 106000],\n",
       "       [    57,  26000],\n",
       "       [    57,  74000],\n",
       "       [    38,  71000],\n",
       "       [    49,  88000],\n",
       "       [    52,  38000],\n",
       "       [    50,  36000],\n",
       "       [    59,  88000],\n",
       "       [    35,  61000],\n",
       "       [    37,  70000],\n",
       "       [    52,  21000],\n",
       "       [    48, 141000],\n",
       "       [    37,  93000],\n",
       "       [    37,  62000],\n",
       "       [    48, 138000],\n",
       "       [    41,  79000],\n",
       "       [    37,  78000],\n",
       "       [    39, 134000],\n",
       "       [    49,  89000],\n",
       "       [    55,  39000],\n",
       "       [    37,  77000],\n",
       "       [    35,  57000],\n",
       "       [    36,  63000],\n",
       "       [    42,  73000],\n",
       "       [    43, 112000],\n",
       "       [    45,  79000],\n",
       "       [    46, 117000],\n",
       "       [    58,  38000],\n",
       "       [    48,  74000],\n",
       "       [    37, 137000],\n",
       "       [    37,  79000],\n",
       "       [    40,  60000],\n",
       "       [    42,  54000],\n",
       "       [    51, 134000],\n",
       "       [    47, 113000],\n",
       "       [    36, 125000],\n",
       "       [    38,  50000],\n",
       "       [    42,  70000],\n",
       "       [    39,  96000],\n",
       "       [    38,  50000],\n",
       "       [    49, 141000],\n",
       "       [    39,  79000],\n",
       "       [    39,  75000],\n",
       "       [    54, 104000],\n",
       "       [    35,  55000],\n",
       "       [    45,  32000],\n",
       "       [    36,  60000],\n",
       "       [    52, 138000],\n",
       "       [    53,  82000],\n",
       "       [    41,  52000],\n",
       "       [    48,  30000],\n",
       "       [    48, 131000],\n",
       "       [    41,  60000],\n",
       "       [    41,  72000],\n",
       "       [    42,  75000],\n",
       "       [    36, 118000],\n",
       "       [    47, 107000],\n",
       "       [    38,  51000],\n",
       "       [    48, 119000],\n",
       "       [    42,  65000],\n",
       "       [    40,  65000],\n",
       "       [    57,  60000],\n",
       "       [    36,  54000],\n",
       "       [    58, 144000],\n",
       "       [    35,  79000],\n",
       "       [    38,  55000],\n",
       "       [    39, 122000],\n",
       "       [    53, 104000],\n",
       "       [    35,  75000],\n",
       "       [    38,  65000],\n",
       "       [    47,  51000],\n",
       "       [    47, 105000],\n",
       "       [    41,  63000],\n",
       "       [    53,  72000],\n",
       "       [    54, 108000],\n",
       "       [    39,  77000],\n",
       "       [    38,  61000],\n",
       "       [    38, 113000],\n",
       "       [    37,  75000],\n",
       "       [    42,  90000],\n",
       "       [    37,  57000],\n",
       "       [    36,  99000],\n",
       "       [    60,  34000],\n",
       "       [    54,  70000],\n",
       "       [    41,  72000],\n",
       "       [    40,  71000],\n",
       "       [    42,  54000],\n",
       "       [    43, 129000],\n",
       "       [    53,  34000],\n",
       "       [    47,  50000],\n",
       "       [    42,  79000],\n",
       "       [    42, 104000],\n",
       "       [    59,  29000],\n",
       "       [    58,  47000],\n",
       "       [    46,  88000],\n",
       "       [    38,  71000],\n",
       "       [    54,  26000],\n",
       "       [    60,  46000],\n",
       "       [    60,  83000],\n",
       "       [    39,  73000],\n",
       "       [    59, 130000],\n",
       "       [    37,  80000],\n",
       "       [    46,  32000],\n",
       "       [    46,  74000],\n",
       "       [    42,  53000],\n",
       "       [    41,  87000],\n",
       "       [    58,  23000],\n",
       "       [    42,  64000],\n",
       "       [    48,  33000],\n",
       "       [    44, 139000],\n",
       "       [    49,  28000],\n",
       "       [    57,  33000],\n",
       "       [    56,  60000],\n",
       "       [    49,  39000],\n",
       "       [    39,  71000],\n",
       "       [    47,  34000],\n",
       "       [    48,  35000],\n",
       "       [    48,  33000],\n",
       "       [    47,  23000],\n",
       "       [    45,  45000],\n",
       "       [    60,  42000],\n",
       "       [    39,  59000],\n",
       "       [    46,  41000],\n",
       "       [    51,  23000],\n",
       "       [    50,  20000],\n",
       "       [    36,  33000],\n",
       "       [    49,  36000]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_mod = LogisticRegression()\n",
    "log_mod.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "Model Performance for Training Set\n",
      "Confusion Matrix :\n",
      "[[165  14]\n",
      " [ 30  71]]\n",
      "accuracy is 0.8428571428571429\n",
      "Error rate is 0.15714285714285714\n",
      "               Classification Report  \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88       179\n",
      "           1       0.84      0.70      0.76       101\n",
      "\n",
      "    accuracy                           0.84       280\n",
      "   macro avg       0.84      0.81      0.82       280\n",
      "weighted avg       0.84      0.84      0.84       280\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "Model Performance for Testing Set\n",
      "Confusion Matrix :\n",
      "[[71  7]\n",
      " [10 32]]\n",
      "accuracy is 0.8583333333333333\n",
      "Error rate is 0.14166666666666666\n",
      "               Classification Report  \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89        78\n",
      "           1       0.82      0.76      0.79        42\n",
      "\n",
      "    accuracy                           0.86       120\n",
      "   macro avg       0.85      0.84      0.84       120\n",
      "weighted avg       0.86      0.86      0.86       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "print('-----------------------------------------------------------------')\n",
    "print('Model Performance for Training Set')\n",
    "y_train_predict = log_mod.predict(x_train)\n",
    "cm1 = confusion_matrix(y_train,y_train_predict)\n",
    "print('Confusion Matrix :')\n",
    "print(cm1)\n",
    "tp = cm1[0][0]\n",
    "tn = cm1[1][1]\n",
    "fp = cm1[1][0]\n",
    "fn = cm1[0][1]\n",
    "ac1 = accuracy_score(y_train,y_train_predict)\n",
    "print('accuracy is {}'.format(ac1))\n",
    "error_rate1 = (fp+fn)/(fp+fn+tn+tp)\n",
    "print('Error rate is {}'.format(error_rate1))\n",
    "print('               Classification Report  ')\n",
    "print(' ')\n",
    "print(classification_report(y_train,y_train_predict))\n",
    "print('-----------------------------------------------------------------')\n",
    "print('Model Performance for Testing Set')\n",
    "y_test_predict = log_mod.predict(x_test)\n",
    "cm1 = confusion_matrix(y_test,y_test_predict)\n",
    "print('Confusion Matrix :')\n",
    "print(cm1)\n",
    "tp = cm1[0][0]\n",
    "tn = cm1[1][1]\n",
    "fp = cm1[1][0]\n",
    "fn = cm1[0][1]\n",
    "ac1 = accuracy_score(y_test,y_test_predict)\n",
    "print('accuracy is {}'.format(ac1))\n",
    "error_rate1 = (fp+fn)/(fp+fn+tn+tp)\n",
    "print('Error rate is {}'.format(error_rate1))\n",
    "print('               Classification Report  ')\n",
    "print(' ')\n",
    "print(classification_report(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure! Here's an explanation of each term:\n",
    "\n",
    "1. Linear Regression:\n",
    "   - Linear regression is a supervised machine learning algorithm used for predicting a continuous target variable based on one or more input features.\n",
    "   - It assumes a linear relationship between the input features and the target variable and finds the best-fit line that minimizes the sum of squared errors.\n",
    "   - The algorithm calculates coefficients and an intercept to estimate the target variable.\n",
    "   - Linear regression is commonly used for tasks such as predicting house prices, stock prices, or sales revenue.\n",
    "\n",
    "2. Logistic Regression:\n",
    "   - Logistic regression is another supervised machine learning algorithm, but it is used for binary classification tasks, where the target variable has two classes (e.g., 0/1, True/False).\n",
    "   - It models the probability of an event occurring by applying the logistic function to a linear combination of the input features.\n",
    "   - Logistic regression estimates coefficients for the input features and uses them to make predictions about the probability of belonging to a particular class.\n",
    "   - It is commonly used for tasks like predicting whether an email is spam or not, or whether a patient has a disease or not.\n",
    "\n",
    "3. Confusion Matrix:\n",
    "   - A confusion matrix is a table that summarizes the performance of a classification model.\n",
    "   - It provides a detailed breakdown of the model's predictions and the actual outcomes, organized into different categories or classes.\n",
    "   - A typical confusion matrix includes metrics such as true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).\n",
    "   - It helps in assessing the model's accuracy and identifying potential sources of error.\n",
    "\n",
    "4. Error Rate:\n",
    "   - Error rate, also known as misclassification rate, is the proportion of incorrectly classified instances over the total number of instances.\n",
    "   - It measures the overall accuracy of a classification model by considering the combined errors made in predicting both positive and negative instances.\n",
    "   - Error rate can be calculated as (FP + FN) / (TP + TN + FP + FN).\n",
    "\n",
    "5. Accuracy Rate:\n",
    "   - Accuracy rate is the proportion of correctly classified instances over the total number of instances.\n",
    "   - It measures the overall correctness of a classification model by considering both true positive and true negative instances.\n",
    "   - Accuracy rate can be calculated as (TP + TN) / (TP + TN + FP + FN).\n",
    "\n",
    "6. Classification Report:\n",
    "   - A classification report is a summary of various evaluation metrics for a classification model, including precision, recall, F1-score, and support.\n",
    "   - Precision measures the proportion of true positive predictions out of all positive predictions, indicating the model's ability to avoid false positives.\n",
    "   - Recall, also known as sensitivity or true positive rate, measures the proportion of true positive predictions out of all actual positive instances, indicating the model's ability to avoid false negatives.\n",
    "   - F1-score is the harmonic mean of precision and recall, providing a balanced measure of a model's performance.\n",
    "   - Support represents the number of instances in each class used for calculating the metrics.\n",
    "   - A classification report is helpful in assessing the model's performance on each class and understanding the trade-offs between precision and recall.\n",
    "\n",
    "These terms are commonly used in machine learning and provide insights into different aspects of model performance, evaluation, and the types of problems they are suitable for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
